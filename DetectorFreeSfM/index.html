<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="width=device-width, initial-scale=1">
    <meta name="description" content="Detector-Free Structure from Motion eliminates the requirement of keypoint detection and can recover poses even on challenging texture-poor scenes." />
    <title>Detector-Free Structure from Motion</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <style>
      body {
        background: #fdfcf9 no-repeat fixed top left;
        font-family:'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col">
            <h2>Detector-Free Structure from Motion</h2>
            <h4 style="color:#6e6e6e;"> Arxiv Preprint, 1st of Image Matching Challenge 2023</h4>
            <hr>
            <h6> <a href="https://github.com/hxy-123" target="_blank">Xingyi He</a><sup>1</sup>,
                 <a href="https://jiamingsun.ml/" target="_blank">Jiaming Sun</a><sup>2</sup>, 
                 <a href="https://github.com/wyf2020" target="_blank">Yifan Wang</a><sup>1</sup>, 
                 <a href="https://pengsida.net/" target="_blank">Sida Peng</a><sup>1</sup>, 
                 <a href="https://www.cs.utexas.edu/~huangqx/" target="_blank">Qixing Huang</a><sup>3</sup>, 
                <a href="http://www.cad.zju.edu.cn/bao/" target="_blank">Hujun Bao</a><sup>1</sup>,
                <a href="http://xzhou.me" target="_blank">Xiaowei Zhou</a><sup>1</sup></h6>
            <p> <sup>1</sup>State Key Lab of CAD & CG, Zhejiang University &nbsp;&nbsp; 
                <sup>2</sup>Image Derivative Inc. &nbsp;&nbsp; 
                <sup>3</sup>The University of Texas at Austin
                <br>
            </p>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="files/main_paper.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="code (coming soon)" href="https://github.com/zju3dv/DetectorFreeSfM" role="button" 
                    target="_blank" disabled=1>
                <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="files/supp.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="dataset (coming soon)" href="" role="button" 
                    target="_blank" disabled=1>
                <i class="fa fa-github-alt"></i> Dataset </a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5" class="text-center"> 
              TL;DR: We propose a detector-free structure from motion framework that eliminates the requirement of keypoint detection and can recover poses even on challenging texture-poor scenes.
            </h6>
            <br>
            <video id="demo" width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="inspect_vid">
                  <source src="images/first_page_demo.m4v" type="video/mp4">
            </video>

            <br>

            <div><b style="color:#fd5638; font-size:large" id="demo-warning"></b>
              <br>
              <br>
          <p class="text-justify">
            We propose a new structure-from-motion framework to recover accurate camera poses and point clouds from unordered images. Traditional SfM systems typically rely on the successful detection of repeatable keypoints across multiple views as the first step, which is difficult for texture-poor scenes, and poor keypoint detection may break down the whole SfM system. We propose a new detector-free SfM framework to draw benefits from the recent success of detector-free matchers to avoid the early determination of keypoints, while solving the multi-view inconsistency issue of detector-free matchers. Specifically, our framework first reconstructs a coarse SfM model from quantized detector-free matches. Then, it refines the model by a novel iterative refinement pipeline, which iterates between an attention-based multi-view matching module to refine feature tracks and a geometry refinement module to improve the reconstruction accuracy. Experiments demonstrate that the proposed framework outperforms existing detector-based SfM systems on common benchmark datasets. We also collect a texture-poor SfM dataset to demonstrate the capability of our framework to reconstruct texture-poor scenes. The submission based on our framework achieves the $\textbf{first place}$ in Image Matching Challenge 2023.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- compare -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Motivation</h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
              For the texture-poor scene, detector-based SfM fails due to the poor repeatability of detected keypoints at the beginning:</p>
            </p>
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/motivation.mov" type="video/mp4">
            </video>

            <p class="text-justify">
              Our detector-free SfM framework leverages detector-free matching and achieves complete reconstruction with highly accurate camera poses:</p>
            </p>
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/our_solution.mov" type="video/mp4">
            </video>

        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Pipeline overview</h3>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/our_pipeline.mov" type="video/mp4">
            </video>

            <p class="text-justify">
              Our framework reconstruct the scene with a coarse-to-fine manner to solve the multi-view inconsistency problem of detector-free matchers.
              Beginning with a collection of unordered images, the $\textbf{Coarse SfM}$ stage generates an initial SfM model based on multi-view matches from a detector-free matcher.
              Then, the $\textbf{Iterative Refinement}$ stage improves the accuracy of the SfM model by alternating between the feature track refinement module and the geometry refinement module.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- compare -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Qualitative comparison on IMC 2021 dataset</h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
              On the scenes collected from internet and with large viewpoint and illumination changes, our framework achieves more accurate poses estimation.</p>
            </p>
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/results_imc.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- compare -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Qualitative comparison on the proposed Texture-Poor SfM dataset</h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
              Due to the severe low-textured scenario and viewpoint changes in the Texture-Poor SfM dataset, detector-based methods struggle with poor keypoint detection and lead to failed reconstruction. Thanks to the detector-free design, our framework achieves significantly higher accuracy and more complete reconstructions.
            </p>
            </p>
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/results_lowtexture.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Application -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Applications</h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
              The recovered poses by our framework on challenging scenes such as texture-poor objects can benefit the downstream tasks, including novel view synthesis and dense reconstruction.
            </p>
            </p>
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/applications.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>
@inproceedings{
    he2023dfsfm,
    title={Detector-Free Structure from Motion},
    author={Xingyi He and Jiaming Sun and Yifan Wang and Sida Peng and Qixing Huang and Hujun Bao and Xiaowei Zhou},
    booktitle={arxiv},
    year={2023}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

  <script type="text/javascript">
    function changePlaybackSpeed(speed)
        {
            document.getElementById('inspect_vid').playbackRate = speed;
        }
        changePlaybackSpeed(0.25)

    var demo = document.getElementById("demo");
    var startTime;
    var timeout = undefined;
    demo.addEventListener("loadstart", function() {
      startTime = Date.now();
      timeout = setTimeout(function () {
        var demoWarning = document.getElementById("demo-warning");
        var giteeLink = document.createElement("a");
        giteeLink.innerText = "mirror hosted in mainland China";
        giteeLink.href = "https://project-pages-1255496016.cos-website.ap-shanghai.myqcloud.com/loftr/";
        // var bilibiliLink = document.createElement("a");
        // var youtubeLink = document.createElement("a");
        // bilibiliLink.innerText = "BiliBili";
        // bilibiliLink.href = "";
        // youtubeLink.innerText = "YouTube";
        // youtubeLink.href = "";

        demoWarning.append("Loading the videos took too long, you can optionally visit this site in the ", giteeLink, ".");
        // demoWarning.append("Loading the video took too long, you can optionally watch it on Bilibili", bilibiliLink, " or YouTube", youtubeLink, ".");
        clearTimeout(timeout);
        timeout = undefined;
      }, 6000);
    });
    demo.addEventListener("loadeddata", function() {
      if (timeout) {
        clearTimeout(timeout);
        timeout = undefined;
      }
    });
//     var source = document.createElement("source");
//     source.setAttribute("src", "images/loftr-homepage-demo.mp4");
//     source.setAttribute("type", "video/webm");
//     demo.appendChild(source);
  </script>
  <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>
</html>
