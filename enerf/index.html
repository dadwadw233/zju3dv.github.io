<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ENeRF</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>Efficient Neural Radiance Fields for Interactive Free-viewpoint Video</h2>
            <!-- <h4 style="color:#5a6268;">CVPR 2021 (Best Paper Candidate)</h4> -->
            <hr>
            <h6> <a href="https://haotongl.github.io" target="_blank">Haotong Lin</a>*, 
                 <a href="https://pengsida.net" target="_blank">Sida Peng</a>*, 
                 <a href="https://github.com/dendenxu" target="_blank">Zhen Xu</a>, 
                 <a href="https://github.com/YYZmadrid" target="_blank">Yunzhi Yan</a>, 
                 <a href="https://chingswy.github.io/" target="_blank">Qing Shuai</a>, 
                Hujun Bao,
                <a href="https://xzhou.me" target="_blank">Xiaowei Zhou</a></h6>
            <p>State Key Lab of CAD & CG, Zhejiang University <br> * denotes equal contribution</p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://zjueducn-my.sharepoint.com/:b:/g/personal/haotongl_zju_edu_cn/EbyOlg4IVdpAk1QEG2TiY5sBsSjuUpvQhew4roNT3EbIqw?e=rHbQeO" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/zju3dv/enerf" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code (Coming soon)</a> </p>
              </div> -->
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/zju3dv/ENeRF" role="button" target="_blank">
                    <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://zjueducn-my.sharepoint.com/:f:/g/personal/pengsida_zju_edu_cn/Eo9zn4x_xcZKmYHZNjzel7gBdWf_d4m-pISHhPWB-GZBYw?e=Hf4mz7" role="button">
                    <i class="fa fa-database"></i> Data</a> </p>
              </div> -->
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/supp.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary</a> </p>
              </div> -->
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <!-- <h6 style="color:#8899a5"> el.</h6> -->
            <video width="60%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/ground_haotong.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-left">This paper aims to tackle the challenge of efficiently producing interactive free-viewpoint videos. Some recent works equip neural radiance fields with image encoders, enabling them to generalize across scenes. When processing dynamic scenes, they can simply treat each video frame as an individual scene and perform novel view synthesis to generate free-viewpoint videos. However, their rendering process is slow and cannot support interactive applications. A major factor is that they sample lots of points in empty space when inferring radiance fields. We propose a novel scene representation, called ENeRF, for the fast creation of interactive free-viewpoint videos. Specifically, given multi-view images at one frame, we first build the cascade cost volume to predict the coarse geometry of the scene. The coarse geometry allows us to sample few points near the scene surface, thereby significantly improving the rendering speed. This process is fully differentiable, enabling us to jointly learn the depth prediction and radiance field networks from RGB images. Experiments on multiple benchmarks show that our approach exhibits competitive performance while being at least 60 times faster than previous generalizable radiance field methods. </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- overview video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Overview video</h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/-qHwpuzFUv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- street dance results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Interactive free-viewpoint video demo on the ZJU-MoCap and ST-NeRF datasets</h3>
            <hr style="margin-top:0px">
            <video width="75%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/313_ft_compress.mp4" type="video/mp4">
            </video>
            <video width="75%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/stnerf_black.mp4" type="video/mp4">
            </video>
            <video width="75%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/stnerf_taekwondo.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- multiview results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>More results on dynamic scenes</h3>
            <hr style="margin-top:0px">
            <!-- <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Novel view synthesis of dynamic human</h4> -->
            <video width="75%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/ground_tianhang.mp4" type="video/mp4">
            </video>
            <video width="75%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/haotongl/imgbed/master/enerf/ground_shenting.mp4" type="video/mp4">
            </video>
            <!-- <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted=""> -->
                <!-- <source src="images/4-view-video-2.m4v" type="video/mp4"> -->
            <!-- </video> -->

            <!-- <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Novel view synthesis of frame 1</h4> -->
            <!-- <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted=""> -->
            <!--     <source src="images/4-view-first-frame.m4v" type="video/mp4"> -->
            <!-- </video> -->

            <!-- <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">3D reconstruction</h4> -->
            <!-- <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted=""> -->
                <!-- <source src="images/4-view-recon.m4v" type="video/mp4"> -->
            <!-- </video> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{lin2022efficient,
  title={Efficient Neural Radiance Fields with Learned Depth-Guided Sampling},
  author={Lin, Haotong and Peng, Sida and Xu, Zhen and Yan, Yunzhi and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
  booktitle={SIGGRAPH Asia Conference Proceedings},
  year={2022}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
