<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- 不知道这里是干嘛的，还没改? -->
  <meta name="description"
        content="NeuMesh encodes the neural implicit field with disentangled geometry and texture features on a mesh scaffold, thereby enables mesh-guided geometry deformation, texture swapping, filling and painting.">
  <meta name="keywords" content="NeuMesh, Neural Rendering, Scene Editing, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="./static/images/thumbnail.png"/>
  <!--这里是链接图表的icon-->
  <!-- <link rel="icon"
        type="image/x-icon"
        href="./static/images/sun.png"/> -->

  <!-- This shown in top of the window-->
  <title>
    SplatLoc
  </title>


  </script>

  <!-- <script type="module"
          src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <!-- <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css"/>
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css"/>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/zju3dv/Vox-Surf"> Vox-Surf</a>
          <a class="navbar-item" href="https://github.com/zju3dv/Vox-Fusion"> Vox-Fusion</a>
          <a class="navbar-item" href="https://zju3dv.github.io/nis_slam"> NIS-SLAM</a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <!-- <div class="column is-9 has-text-centered">
          <img style="width: 200%; transform: translate(0%, 0%);" src="./static/images/NIS-SLAM.png" alt="NIS-SLAM"/>
        </div> -->
      </div>
      <div class="container has-text-centered">
        <h1 class="title is-1 publication-title">
          SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality
        </h1>
        <!-- confrence or journal -->
        <!-- <h1 class="title is-size-3" style="color:#5a6268;">TVCG 2024 (ISMAR Journal Track)</h1> -->
        <div class="is-size-5 publication-authors">
          <div class="author-block">
            <a href="https://github.com/zhaihongjia">Hongjia Zhai</a><sup>1</sup>,</div>
          <div class="author-block">
            <a href="https://github.com/zju3dv">Xiyu Zhang</a><sup>1</sup>,</div>
          <div class="author-block">
            <a href="https://github.com/zju3dv">Boming Zhao</a><sup>1</sup>,</div>
            <div class="author-block">
            <a href="https://github.com/zju3dv">Hai Li</a><sup>2</sup>,</div>
            <div class="author-block">
              <a href="https://github.com/zju3dv">Yijia He</a><sup>2</sup>,</div>
              <div class="author-block">
                <a href="https://github.com/zju3dv">Zhaopeng Cui</a><sup>1</sup>,</div>
          <div class="author-block">
            <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a><sup>1</sup>,</div>
          <div class="author-block">
            <a href="http://www.cad.zju.edu.cn/home/gfzhang/">Guofeng Zhang</a><sup>1</sup></div>
        </div>

        <div class="is-size-5 publication-authors">
          <!-- * denotes equal contribution <br> -->
          <span class="author-block"><sup>1</sup>State Key Lab of CAD & CG, Zhejiang University,</span>
          <span class="author-block"><sup>2</sup>RayNeo</span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
                <a href="https://arxiv.org/abs/2409.14067"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            <span class="link-block">
                <a href="https://arxiv.org/abs/2409.14067"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/zhaihongjia/SplatLoc"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="https://raw.githubusercontent.com/ybbbbt/open_access_assets/main/neumesh/hybrid_edit.mp4"
                type="video/mp4">
      </video> -->
      <img style="width: 100%;" src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/teaser.png" alt="SplatLoc architecture."/>
      <!-- <h2 class="subtitle has-text-centered"> -->
      <div class="content has-text-justified">
        <p>
        We present SplatLoc, an efficient and novel visual localization approach designed for Augmented Reality (AR). 
        As illustrated in the figure, our system utilizes monocular RGB-D frames to reconstruct the scene using 3D Gaussian primitives. 
        Additionally, with our learned unbiased 3D descriptor fields, we achieve 6-DoF camera pose estimation through precise 2D-3D feature matching. 
        We demonstrate the potential AR applications of our system, such as virtual content insertion and physical collision simulation. 
        We highlight virtual objects with red boxes.
        </p>
      </div>
      <!-- </h2> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fifth-sixths">
        <h2 class="title is-3" style="color:#ff9c7b;">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual localization plays an important role in the applications of Augmented Reality (AR), which enable AR devices to obtain their 6-DoF pose in the pre-build map 
            in order to render virtual content in real scenes. However, most existing approaches can not perform novel view rendering and require large storage capacities for maps. 
            To overcome these limitations, we propose an efficient visual localization method capable of high-quality rendering with fewer parameters. Specifically, our approach 
            leverages 3D Gaussian primitives as the scene representation. To ensure precise 2D-3D correspondences for pose estimation, we develop an unbiased 3D scene-specific 
            descriptor decoder for Gaussian primitives, distilled from a constructed feature volume. Additionally, we introduce a salient 3D landmark selection algorithm that 
            selects a suitable primitive subset based on the saliency score for localization. We further regularize key Gaussian primitives to prevent anisotropic effects, which 
            also improves localization performance. Extensive experiments on two widely used datasets demonstrate that our method achieves superior or comparable rendering and 
            localization performance to state-of-the-art implicit-based visual localization approaches.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2" style="color:#ff9c7b;">Supplemental Video</h2>
          <video id="functions" autoplay controls muted loop playsinline weight="100%">
            <source src="./static/videos/ismar24b-sub1174-i8.mp4"
                    type="video/mp4">
          </video>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<hr/>

<section class="section">
<!-- Framework Overview -->
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 class="title is-3 has-text-centered" style="color:#ff9c7b;"><p>Method</p></h2>
      <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Reconstruction Process</p></h3>
      <div class="has-text-centered">
        <img style="width: 100%;" src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/reconstruction.png"
             alt="SplatLoc Reconstruction."/>
      </div>
      <p>
        We incrementally initialize the Gaussian primitives, and each primitive is associated with position $\mu$, rotation $q$, scale $s$, opacity $\sigma$, color $c$, and 3D landmark score $a$. 
        For key Gaussian primitives, we perform soft isotropy and scale regularization to mitigate the anisotropic results. 
        The color loss $\mathcal{L}_{c}$, depth loss $\mathcal{L}_d$, 3D landmark loss $\mathcal{L}_m$, and regularization loss $\mathcal{L}_{reg}$ 
        are used to optimize the properties of each primitive via differentiable rasterization.
      </p>
      <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Descriptor Learning</p></h3>
      <div class="has-text-centered">
        <img style="width: 100%;" src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/feat_distill.png"
             alt="SplatLoc Reconstruction."/>
      </div>
      <p>
        The pipeline of our unbiased 3D primitive descriptor learning. We first encode images based on the 2D CNN model (SuperPoint) 
        to obtain the multi-view feature maps and construct the 3D scene feature volume according to the depth and pose information. 
        To enhance the representation ability of the 3D feature decoder, we use multi-resolution parametric encoding to aid the 3D scene-specific descriptor learning. 
        Besides, we only sample descriptors on the scene surface for effective distillation.
      </p>
    </div>
  </div>

</section>


<section class="section">
    <div class="container is-max-desktop">
    <div class="content has-text-justified">
    <h2 class="title is-3 has-text-centered" style="color:#ff9c7b;"><p>Experiments</p></h2>
    <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Visual Localization</p></h3>
    <div class="has-text-centered">
      <img style="width: 100%;" src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/localization_results.png" alt="Visual Localization."/>
      <!-- <img style="width: 100%;" src="/home/hongjia/Documents/open_access_assets/SplatLoc/images/localization_results.png" alt="Visual Localization."/> -->
    </div>
    <p><strong><font size="4">Visual Localization Performance:</font></strong> We report median translation and rotation errors (cm, degree) on Replica and 12-Scenes.</p>

    <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Novel view synthesis</p></h3>
    <div class="has-text-centered">
      <img style="width: 100%;" src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/images/rendering_results.png" alt="Novel view synthesis."/>
      <!-- <img style="width: 100%;" src="/home/hongjia/Documents/open_access_assets/SplatLoc/images/rendering_results.png" alt="Novel view synthesis."/> -->
    </div>
    <p><strong><font size="4">Novel View Synthesis Performance:</font></strong> We report PSNR, SSIM, LPIPS metrics on Replica.</p>

    <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>AR Applications</p></h3>
      <!-- <div class="has-text-centered"> -->
        <video style="width: 24%;" id="functions" autoplay controls muted loop playsinline height="100%">
          <source src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/videos/ar_demos/scene_video.mp4" type="video/mp4">
          <!-- <source src="/home/hongjia/Documents/open_access_assets/SplatLoc/videos/ar_demos/scene_video.mp4" type="video/mp4"> -->
        </video>
        <video style="width: 24%;" id="functions" autoplay controls muted loop playsinline height="100%">
          <source src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/videos/ar_demos/room0_ar_video_logo_ours_pose.mp4" type="video/mp4">
          <!-- <source src="/home/hongjia/Documents/open_access_assets/SplatLoc/videos/ar_demos/room0_ar_video_logo_ours_pose.mp4" type="video/mp4"> -->
        </video>
        <video style="width: 24%;" id="functions" autoplay controls muted loop playsinline height="100%">
          <source src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/videos/ar_demos/test_frame_165_compress.mp4" type="video/mp4">
          <!-- <source src="/home/hongjia/Documents/open_access_assets/SplatLoc/videos/ar_demos/test_frame_165_compress.mp4" type="video/mp4"> -->
        </video>
        <video style="width: 24%;" id="functions" autoplay controls muted loop playsinline height="100%">
          <source src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/videos/ar_demos/train_frame_880_compress.mp4" type="video/mp4">
          <!-- <source src="/home/hongjia/Documents/open_access_assets/SplatLoc/videos/ar_demos/train_frame_880_compress.mp4" type="video/mp4"> -->
        </video>
      <p><strong><font size="4">AR Applications:</font></strong> We show two different AR applications on scene $\texttt{Room 0}$ from the Replica dataset.
        $\textbf{(1) Insert Objects}$: we virtual AR objects and $\texttt{IEEE VR}$ text logo into real scene.
        $\textbf{(2) Physical collision}$: we place a virtual blanket in the scene and let it fall naturally to simulate physical collision between our reconstructed scene geometry and the virtual blanket.
        As can be seen, our approach can perform high-quality rendering and handle the collision and occlusion between real and virtual content very well.</p>


    <h3 class="title is-5 has-text-centered" style="color:#f55d26;"><p>Localization Process</p></h3>
      <div class="has-text-centered">
        <video style="width: 70%;" id="functions" autoplay controls muted loop playsinline height="100%">
          <source src="https://raw.githubusercontent.com/zhaihongjia/open_access_assets/main/SplatLoc/videos/loc_process/apt2_living_match_gt_traj_compress.mp4" type="video/mp4">
          <!-- <source src="/home/hongjia/Documents/open_access_assets/SplatLoc/videos/loc_process/apt2_living_match_gt_traj_compress.mp4" type="video/mp4"> -->
        </video>
      <p><strong><font size="4">Localization Process:</font></strong> We show the $\textcolor{red}{\text{estimeted pose}}$, $\textcolor{green}{\text{2D-3D correspondece}}$, and $\textcolor{black}{\text{GT pose}}$ in different colors.</p>
      </div>
    </div>

    <br/>

</section>

<hr/>
<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{splatloc,
      author={Zhai, Hongjia and Zhang, Xiyu and Zhao Boming and Li, Hai and He, Yijia and Cui, Zhaopeng and Bao, Hujun and Zhang, Guofeng},
      journal={arXiv preprint arXiv:2409.14067}, 
      title={SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality}, 
      year={2024},
}
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      Thanks to <a href="https://www.flaticon.com/" target="_blank">Flaticon</a> for providing beautiful icons.
      The website template is borrowed from <a href="https://hypernerf.github.io/" target="_blank">HyperNeRF</a>.
    </div>
  </div>
</footer>

<script>
  MathJax = {
    tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
  };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F5RT7HMEN2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-F5RT7HMEN2');
</script>

<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
