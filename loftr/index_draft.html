<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LoFTR: Detector-Free Local Feature Matching with Transformers</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <style>
      body {
        background: #fdfcf9 no-repeat fixed top left;
        font-family:'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col">
            <h2>LoFTR: Detector-Free Local Feature Matching with Transformers</h2>
            <h5 style="color:#6e6e6e;font-weight: bold;"> CVPR 2021 </h5>
            <hr>
            <h6> <a href="https://jiamingsun.ml/" target="_blank">Jiaming Sun</a><sup>1,2*</sup>, 
                 <a href="https://zehongs.github.io/" target="_blank">Zehong Shen</a><sup>1*</sup>, 
                 <a href="https://github.com/angshine" target="_blank">Yuang Wang</a><sup>1*</sup>, 
                <a href="http://www.cad.zju.edu.cn/bao/" target="_blank">Hujun Bao</a><sup>1</sup>,
                <a href="http://xzhou.me" target="_blank">Xiaowei Zhou</a><sup>1</sup></h6>
            <p> <sup>1</sup>State Key Lab of CAD & CG, Zhejiang University &nbsp;&nbsp; 
                <sup>2</sup>SenseTime Research
                <br>
                <sup>*</sup> denotes equal contribution
            </p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2103.00000.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="code_soon" href="https://github.com/zju3dv/LoFTR" role="button" 
                    target="_blank" disabled=1 onmouseover="changeText(' Around April ', 'code_soon')" onmouseout="changeText('Code (comming soon)', 'code_soon')">
                <i class="fa fa-github-alt"></i> Code (comming soon)</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="files/LoFTR-suppmat.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary</a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <!-- <h6 style="color:#8899a5"> TL;DR: LoFTR is a .</h6> -->
            <video width="70%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/short_demo.m4v" type="video/mp4">
            </video>
              <!-- <br><br> -->
          <p class="text-left">We present a novel method for image local feature matching. Instead of performing image feature detection, description and matching sequentially, we propose to Ô¨Årst establish pixel-wise dense matches in a coarse level and later refine the good matches in a fine level. In contrast to dense methods that use cost volume to search correspondences, we use self and cross attention layer in Transformers to obtain feature descriptors that are conditioned on both images. The global receptive field provided by Transformers enables our method to produce dense matches in low-texture areas, where feature detectors usually struggle to produce repeatable interest points. The experiments on indoor and outdoor datasets show that our system outperforms state-of-the-art methods by a large margin.</p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- overview video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Pipeline overview</h3>
            <hr style="margin-top:0px">
            <!-- <div class="embed-responsive embed-responsive-16by9"> -->
                <!-- <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/EpmnpwwaR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
            <!-- </div> -->
                <img class="img-fluid" src="images/loftr-arch.png" alt="LoFTR Architechture">
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- demo video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Video demo and qualitative comparison with <a href="https://psarlin.com/superglue">SuperGlue</a></h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/EpmnpwwaR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- more videos -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>More matching results</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/street_dance.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{sun2021loftr,
  title={LoFTR: Detector-Free Local Feature Matching with Transformers},
  author={Sun, Jiaming and Shen, Zehong and Wang, Yuang and Bao, Hujun and Zhou, Xiaowei},
  journal={CVPR},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

  <script type="text/javascript">
    function changeText(text, elem_id)
        {
            var display = document.getElementById(elem_id);
            display.innerHTML = "";
            display.innerHTML = text;
        }
  </script>
</body>
</html>
