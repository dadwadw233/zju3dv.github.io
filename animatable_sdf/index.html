<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Animatable Implicit Neural Representations for Creating Realistic Avatars from Videos</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h3>Animatable Implicit Neural Representations for Creating Realistic Avatars from Videos</h3>
            <!-- <h5 style="color:#8899a5;"> Under Review </h5> -->
            <h4 style="color:#5a6268;">TPAMI 2024, ICCV 2021</h4>
            <hr>
            <h6> 
              <a href="https://pengsida.net/" target="_blank">Sida Peng</a><sup>1</sup>, 
              <a href="https://zhenx.me/" target="_blank">Zhen Xu</a><sup>1</sup>,
              <a href="https://jtdong.com/" target="_blank">Junting Dong</a><sup>1</sup>, 
              <a href="https://www.cs.cornell.edu/~qqw/" target="_blank">Qianqian Wang</a><sup>2</sup>, 
              <a href="https://zhanghe3z.github.io/" target="_blank">Shangzhan Zhang</a><sup>1</sup>, 
              <a href="https://chingswy.github.io/" target="_blank">Qing Shuai</a><sup>1</sup>, 
              <a href="http://www.cad.zju.edu.cn/home/bao/" target="_blank">Hujun Bao</a><sup>1</sup>,
              <a href="https://xzhou.me" target="_blank">Xiaowei Zhou</a><sup>1</sup></h6>
            <p>
              <sup>1</sup>State Key Lab of CAD & CG, Zhejiang University &nbsp;&nbsp; 
                <sup>2</sup>Cornell University
            <br>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2203.08133.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://pengsida.net/project_page_assets/animatable_sdf/supplementary_material.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary</a> </p>
              </div>
               <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/zju3dv/animatable_nerf" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
              <!-- <div class="column"> -->
              <!--     <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"> -->
              <!--       <i class="fa fa-database"></i> Data</a> </p> -->
              <!-- </div> -->
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5"> This paper is an extension of Animatable NeRF, which has better reconstruction and rendering results.</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/teaser.m4v" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-left">
            This paper addresses the challenge of reconstructing an animatable human model from a multi-view video. Some recent works have proposed to decompose a non-rigidly deforming scene into a canonical neural radiance field and a set of deformation fields that map observation-space points to the canonical space, thereby enabling them to learn the dynamic scene from images. However, they represent the deformation field as translational vector field or SE(3) field, which makes the optimization highly under-constrained. Moreover, these representations cannot be explicitly controlled by input motions. Instead, we introduce a pose-driven deformation field based on the linear blend skinning algorithm, which combines the blend weight field and the 3D human skeleton to produce observation-to-canonical correspondences. Since 3D human skeletons are more observable, they can regularize the learning of the deformation field. Moreover, the pose-driven deformation field can be controlled by input skeletal motions to generate new deformation fields to animate the canonical human model. Experiments show that our approach significantly outperforms recent human modeling methods.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- overview video -->
  <!-- <section> -->
  <!--   <div class="container"> -->
  <!--     <div class="row"> -->
  <!--       <div class="col-12 text-center"> -->
  <!--           <h3>Overview video</h3> -->
  <!--           <hr style="margin-top:0px"> -->
  <!--           <div class="embed-responsive embed-responsive-16by9"> -->
  <!--               <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/BPCAMeBCE-8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
  <!--           </div> -->
  <!--       </div> -->
  <!--     </div> -->
  <!--   </div> -->
  <!-- </section> -->
  <!-- <br> -->

  <!-- 3D reconstruction results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Reconstruction results</h3>
            <hr style="margin-top:0px">
            <h5 style="color:#838283; margin-top:10px"> Comparison on 3D reconstruction from monocular videos</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" style="margin-top:-5px">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/3d_reconstruction1.m4v" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" style="margin-top:-10px">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/3d_reconstruction2.m4v" type="video/mp4">
            </video>

            <h5 style="color:#838283; margin-top:10px"> More reconstruction results</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" style="margin-top:0px">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/3d_reconstruction3.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- rendering results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Rendering results</h3>
            <hr style="margin-top:0px">
            <h5 style="color:#838283; margin-top:10px"> Comparison on novel view synthesis</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/novel_view_synthesis.m4v" type="video/mp4">
            </video>

            <h5 style="color:#838283; margin-top:10px"> Comparison on novel pose synthesis</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/novel_pose_synthesis.m4v" type="video/mp4">
            </video>

            <h5 style="color:#838283; margin-top:10px"> Novel pose synthesis under complex human poses</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/novel_pose_synthesis_complex_poses.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- ablation studies -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Ablation studies</h3>
            <hr style="margin-top:0px">
            <h5 style="color:#838283; margin-top:10px"> Non-rigid deformations captured by the displacement fields</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/displacement_field.m4v" type="video/mp4">
            </video>

            <h5 style="color:#838283; margin-top:10px"> Ablation study on canonical-space viewing direction</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/canonical_space_viewing_direction.m4v" type="video/mp4">
            </video>

            <h5 style="color:#838283; margin-top:10px"> Ablation study on neural feature fields</h5>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="https://raw.githubusercontent.com/pengsida/project_page_assets/master/animatable_sdf/neural_feature_field.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>
@article{peng2024animatable,
    title={Animatable Implicit Neural Representations for Creating Realistic Avatars from Videos},
    author={Peng, Sida and Xu, Zhen and Dong, Junting and Wang, Qianqian and Zhang, Shangzhan and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
    journal={TPAMI},
    year={2024},
    publisher={IEEE}
}
@inproceedings{peng2021animatable,
  title={Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies},
  author={Peng, Sida and Dong, Junting and Wang, Qianqian and Zhang, Shangzhan and Shuai, Qing and Zhou, Xiaowei and Bao, Hujun},
  booktitle={ICCV},
  year={2021}
}
</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
