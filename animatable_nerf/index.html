<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies</h2>
            <h4 style="color:#5a6268;">ICCV 2021</h4>
            <hr>
            <h6> <a href="https://pengsida.net/" target="_blank">Sida Peng</a><sup>1*</sup>, 
                <a href="https://jtdong.com/" target="_blank">Junting Dong</a><sup>1*</sup>, 
                <a href="http://www.cs.cornell.edu/~qqw/" target="_blank">Qianqian Wang</a><sup>2</sup>,
                Shangzhan Zhang<sup>1</sup>,
                Qing Shuai<sup>1</sup>,
                <a href="https://xzhou.me" target="_blank">Xiaowei Zhou</a><sup>1</sup>,
                Hujun Bao<sup>1</sup></h6>
            <p><sup>1</sup>State Key Lab of CAD & CG, Zhejiang University &nbsp;&nbsp; 
                <sup>2</sup>Cornell University
            <br>
            <sup>*</sup> denotes equal contribution </p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2105.02872.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://zjueducn-my.sharepoint.com/:b:/g/personal/pengsida_zju_edu_cn/EQ-UwOnJKVBMteT_SJVxTHkBFM9VIU1vsnJQ0YEVUndWWQ?e=msudZH" role="button" target="_blank">
                    <i class="fa fa-file"></i> Supplementary Material</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/zju3dv/animatable_nerf" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button">
                    <i class="fa fa-database"></i> Data</a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <h6 style="color:#8899a5"> Animatable NeRF can reconstruct an animatable human model from a sparse multi-view video.</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/teaser.m4v" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-left"> This paper addresses the challenge of reconstructing an animatable human model from a multi-view video. Some recent works have proposed to decompose a non-rigidly deforming scene into a canonical neural radiance field and a set of deformation fields that map observation-space points to the canonical space, thereby enabling them to learn the dynamic scene from images. However, they represent the deformation field as translational vector field or SE(3) field, which makes the optimization highly under-constrained. Moreover, these representations cannot be explicitly controlled by input motions. Instead, we introduce neural blend weight fields to produce the deformation fields. Based on the skeleton-driven deformation, blend weight fields are used with 3D human skeletons to generate observation-to-canonical and canonical-to-observation correspondences. Since 3D human skeletons are more observable, they can regularize the learning of deformation fields. Moreover, the learned blend weight fields can be combined with input skeletal motions to generate new deformation fields to animate the human model. Experiments show that our approach significantly outperforms recent human synthesis methods. The code will be available at https://zju3dv.github.io/animatable_nerf/.</p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- overview video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Overview video</h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/eWOSWbmfJo4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- novel pose synthesis results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Comparison on novel pose synthesis</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_pose_synthesis1.m4v" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_pose_synthesis2.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- novel view synthesis results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Comparison on novel view synthesis</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_view_synthesis1.m4v" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_view_synthesis2.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- reposed geometry results -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Reposing the reconstructed geometry</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/reposed_geometry.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{peng2021animatable,
  title={Animatable Neural Radiance Fields for Human Body Modeling},
  author={Peng, Sida and Dong, Junting and Wang, Qianqian and Zhang, Shangzhan and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2105.02872},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
